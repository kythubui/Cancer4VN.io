{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb134fd0-d917-480b-9080-5d3c5b51a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should be True\n",
    "print(torch.cuda.get_device_name(0))  # GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c093eb4-bfdc-4def-b9da-a6750c300e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deb7180-9d17-44c7-978a-013869b3b3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>focus</th>\n",
       "      <th>qa_pair_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_text</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000013_2</td>\n",
       "      <td>Chronic Eosinophilic Leukemia</td>\n",
       "      <td>1</td>\n",
       "      <td>0000013_2-1</td>\n",
       "      <td>information</td>\n",
       "      <td>What is (are) Chronic Eosinophilic Leukemia ?</td>\n",
       "      <td>Key Points\\n                    - Chronic eosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000013_2</td>\n",
       "      <td>Chronic Eosinophilic Leukemia</td>\n",
       "      <td>2</td>\n",
       "      <td>0000013_2-2</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>What are the symptoms of Chronic Eosinophilic ...</td>\n",
       "      <td>Signs and symptoms of chronic eosinophilic leu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000013_2</td>\n",
       "      <td>Chronic Eosinophilic Leukemia</td>\n",
       "      <td>3</td>\n",
       "      <td>0000013_2-3</td>\n",
       "      <td>treatment</td>\n",
       "      <td>What are the treatments for Chronic Eosinophil...</td>\n",
       "      <td>Treatment of chronic eosinophilic leukemia may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000003_5</td>\n",
       "      <td>Childhood Soft Tissue Sarcoma</td>\n",
       "      <td>1</td>\n",
       "      <td>0000003_5-1</td>\n",
       "      <td>information</td>\n",
       "      <td>What is (are) Childhood Soft Tissue Sarcoma ?</td>\n",
       "      <td>Key Points\\n\\t\\t\\t\\t\\t\\t\\t                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000003_5</td>\n",
       "      <td>Childhood Soft Tissue Sarcoma</td>\n",
       "      <td>2</td>\n",
       "      <td>0000003_5-2</td>\n",
       "      <td>susceptibility</td>\n",
       "      <td>Who is at risk for Childhood Soft Tissue Sarco...</td>\n",
       "      <td>Having certain diseases and inherited disorder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0000014_1</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>4</td>\n",
       "      <td>0000014_1-4</td>\n",
       "      <td>exams and tests</td>\n",
       "      <td>How to diagnose Endometrial Cancer ?</td>\n",
       "      <td>Tests that examine the endometrium are used to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0000014_1</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>5</td>\n",
       "      <td>0000014_1-5</td>\n",
       "      <td>outlook</td>\n",
       "      <td>What is the outlook for Endometrial Cancer ?</td>\n",
       "      <td>Certain factors affect prognosis (chance of re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0000014_1</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>6</td>\n",
       "      <td>0000014_1-6</td>\n",
       "      <td>stages</td>\n",
       "      <td>What are the stages of Endometrial Cancer ?</td>\n",
       "      <td>Key Points\\n                    - After endome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0000014_1</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>7</td>\n",
       "      <td>0000014_1-7</td>\n",
       "      <td>treatment</td>\n",
       "      <td>What are the treatments for Endometrial Cancer ?</td>\n",
       "      <td>Key Points\\n                    - There are di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0000014_1</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "      <td>8</td>\n",
       "      <td>0000014_1-8</td>\n",
       "      <td>research</td>\n",
       "      <td>what research (or clinical trials) is being do...</td>\n",
       "      <td>New types of treatment are being tested in cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    document_id                          focus qa_pair_id  question_id  \\\n",
       "0     0000013_2  Chronic Eosinophilic Leukemia          1  0000013_2-1   \n",
       "1     0000013_2  Chronic Eosinophilic Leukemia          2  0000013_2-2   \n",
       "2     0000013_2  Chronic Eosinophilic Leukemia          3  0000013_2-3   \n",
       "3     0000003_5  Childhood Soft Tissue Sarcoma          1  0000003_5-1   \n",
       "4     0000003_5  Childhood Soft Tissue Sarcoma          2  0000003_5-2   \n",
       "..          ...                            ...        ...          ...   \n",
       "724   0000014_1             Endometrial Cancer          4  0000014_1-4   \n",
       "725   0000014_1             Endometrial Cancer          5  0000014_1-5   \n",
       "726   0000014_1             Endometrial Cancer          6  0000014_1-6   \n",
       "727   0000014_1             Endometrial Cancer          7  0000014_1-7   \n",
       "728   0000014_1             Endometrial Cancer          8  0000014_1-8   \n",
       "\n",
       "       question_type                                      question_text  \\\n",
       "0        information      What is (are) Chronic Eosinophilic Leukemia ?   \n",
       "1           symptoms  What are the symptoms of Chronic Eosinophilic ...   \n",
       "2          treatment  What are the treatments for Chronic Eosinophil...   \n",
       "3        information      What is (are) Childhood Soft Tissue Sarcoma ?   \n",
       "4     susceptibility  Who is at risk for Childhood Soft Tissue Sarco...   \n",
       "..               ...                                                ...   \n",
       "724  exams and tests               How to diagnose Endometrial Cancer ?   \n",
       "725          outlook       What is the outlook for Endometrial Cancer ?   \n",
       "726           stages        What are the stages of Endometrial Cancer ?   \n",
       "727        treatment   What are the treatments for Endometrial Cancer ?   \n",
       "728         research  what research (or clinical trials) is being do...   \n",
       "\n",
       "                                           answer_text  \n",
       "0    Key Points\\n                    - Chronic eosi...  \n",
       "1    Signs and symptoms of chronic eosinophilic leu...  \n",
       "2    Treatment of chronic eosinophilic leukemia may...  \n",
       "3    Key Points\\n\\t\\t\\t\\t\\t\\t\\t                    ...  \n",
       "4    Having certain diseases and inherited disorder...  \n",
       "..                                                 ...  \n",
       "724  Tests that examine the endometrium are used to...  \n",
       "725  Certain factors affect prognosis (chance of re...  \n",
       "726  Key Points\\n                    - After endome...  \n",
       "727  Key Points\\n                    - There are di...  \n",
       "728  New types of treatment are being tested in cli...  \n",
       "\n",
       "[729 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/Pedrampedram/CancerGov_QA/data/train-00000-of-00001-95d10b894a8afa4d.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0c3541-85a3-4d9e-a541-6256fbd78dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (583, 7)\n",
      "Shape of validation set: (73, 7)\n",
      "Shape of test set: (73, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Shape of training set: {train_df.shape}\")\n",
    "print(f\"Shape of validation set: {validation_df.shape}\")\n",
    "print(f\"Shape of test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b853c59a-27bf-4bbc-a8cd-f96e80c2bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\nimport torch\\nimport pandas as pd\\nfrom tqdm import tqdm\\n\\n# Load model + tokenizer\\nmodel_id = \"openai/gpt-oss-20b\"\\n#model_id = \"openai/gpt-oss-6.9b\"\\n\\ntokenizer = AutoTokenizer.from_pretrained(model_id)\\nmodel = AutoModelForCausalLM.from_pretrained(\\n    model_id,\\n    torch_dtype=torch.float32  \\n)\\n\\n# Assume test_df has a column \"prompt\"\\nprompts = test_df[\"prompt\"].tolist()\\n\\noutputs = []\\nbatch_size = 2   # adjust depending on your GPU memory\\n\\nfor i in tqdm(range(0, len(prompts), batch_size)):\\n    batch_prompts = prompts[i:i+batch_size]\\n    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\\n    \\n    out_tokens = model.generate(\\n        **inputs,\\n        max_new_tokens=256,\\n        temperature=0.7,\\n        do_sample=True,\\n        pad_token_id=tokenizer.eos_token_id,\\n    )\\n    \\n    decoded_batch = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\\n    outputs.extend(decoded_batch)\\n\\n# Add results to DataFrame\\ntest_df[\"model_output\"] = outputs\\ntest_df.to_csv(\"test_with_outputs.csv\", index=False)\\n\\nprint(\"✅ Finished inference. Results saved to test_with_outputs.csv\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model + tokenizer\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "#model_id = \"openai/gpt-oss-6.9b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32  \n",
    ")\n",
    "\n",
    "# Assume test_df has a column \"prompt\"\n",
    "prompts = test_df[\"prompt\"].tolist()\n",
    "\n",
    "outputs = []\n",
    "batch_size = 2   # adjust depending on your GPU memory\n",
    "\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    batch_prompts = prompts[i:i+batch_size]\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    out_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    decoded_batch = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    outputs.extend(decoded_batch)\n",
    "\n",
    "# Add results to DataFrame\n",
    "test_df[\"model_output\"] = outputs\n",
    "test_df.to_csv(\"test_with_outputs.csv\", index=False)\n",
    "\n",
    "print(\"✅ Finished inference. Results saved to test_with_outputs.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deaa7a6b-dfa7-4d15-a1f9-77cc8c52d9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\nimport torch\\nimport pandas as pd\\nfrom tqdm import tqdm\\n\\n# Load model + tokenizer\\nmodel_id = \"openai/gpt-oss-20b\"\\ntokenizer = AutoTokenizer.from_pretrained(model_id)\\nmodel = AutoModelForCausalLM.from_pretrained(\\n    model_id,\\n    torch_dtype=torch.float32,   # use float32 if CPU only\\n)\\n\\n# Assume test_df has a column \"prompt\"\\nprompts = test_df[\"prompt\"].tolist()\\n\\noutputs = []\\nbatch_size = 2   # adjust depending on your GPU memory\\n\\nfor i in tqdm(range(0, len(prompts), batch_size)):\\n    batch_prompts = prompts[i:i+batch_size]\\n    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\\n    \\n    out_tokens = model.generate(\\n        **inputs,\\n        max_new_tokens=256,\\n        temperature=0.7,\\n        do_sample=True,\\n        pad_token_id=tokenizer.eos_token_id,\\n    )\\n    \\n    decoded_batch = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\\n    outputs.extend(decoded_batch)\\n\\n# Add results to DataFrame\\ntest_df[\"model_output\"] = outputs\\ntest_df.to_csv(\"test_with_outputs.csv\", index=False)\\n\\nprint(\"✅ Finished inference. Results saved to test_with_outputs.csv\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model + tokenizer\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32,   # use float32 if CPU only\n",
    ")\n",
    "\n",
    "# Assume test_df has a column \"prompt\"\n",
    "prompts = test_df[\"prompt\"].tolist()\n",
    "\n",
    "outputs = []\n",
    "batch_size = 2   # adjust depending on your GPU memory\n",
    "\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    batch_prompts = prompts[i:i+batch_size]\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    out_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    decoded_batch = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    outputs.extend(decoded_batch)\n",
    "\n",
    "# Add results to DataFrame\n",
    "test_df[\"model_output\"] = outputs\n",
    "test_df.to_csv(\"test_with_outputs.csv\", index=False)\n",
    "\n",
    "print(\"✅ Finished inference. Results saved to test_with_outputs.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99296b6f-a0f9-4c51-bf42-194676b81aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\\nimport pandas as pd\\nfrom tqdm import tqdm\\n\\n# Load your test dataset\\n# test_df = pd.read_csv(\"your_test_file.csv\")  # make sure test_df has a column \"prompt\"\\n\\n# Model ID\\nmodel_id = \"EleutherAI/gpt-j-6B\"\\n\\n# Initialize tokenizer and model pipeline\\ngenerator = pipeline(\\n    \"text-generation\",\\n    model=model_id,\\n    device=-1  # -1 means CPU\\n)\\n\\nprompts = test_df[\"input\"].tolist()\\noutputs = []\\n\\n# Generate outputs for each prompt\\nfor prompt in tqdm(prompts):\\n    result = generator(\\n        prompt,\\n        max_length=256,   # adjust as needed\\n        do_sample=True,\\n        temperature=0.7\\n    )\\n    outputs.append(result[0][\\'generated_text\\'])\\n\\n# Save results to DataFrame\\ntest_df[\"model_output\"] = outputs\\ntest_df.to_csv(\"test_with_outputs.csv\", index=False)\\nprint(\"✅ Finished inference, results saved to test_with_outputs.csv\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your test dataset\n",
    "# test_df = pd.read_csv(\"your_test_file.csv\")  # make sure test_df has a column \"prompt\"\n",
    "\n",
    "# Model ID\n",
    "model_id = \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "# Initialize tokenizer and model pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    device=-1  # -1 means CPU\n",
    ")\n",
    "\n",
    "prompts = test_df[\"input\"].tolist()\n",
    "outputs = []\n",
    "\n",
    "# Generate outputs for each prompt\n",
    "for prompt in tqdm(prompts):\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=256,   # adjust as needed\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    outputs.append(result[0]['generated_text'])\n",
    "\n",
    "# Save results to DataFrame\n",
    "test_df[\"model_output\"] = outputs\n",
    "test_df.to_csv(\"test_with_outputs.csv\", index=False)\n",
    "print(\"✅ Finished inference, results saved to test_with_outputs.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d72a2b2-c132-4bc5-aa10-ea65a3b4a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "100%|███████████████████████████████████████████| 10/10 [02:37<00:00, 15.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished inference on GPU using accelerate. Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen2-0.5B\"\n",
    "\n",
    "# Load tokenizer + model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,  # FP16 for GPU\n",
    "    device_map=\"auto\"           # let accelerate handle GPU placement\n",
    ")\n",
    "\n",
    "# Do NOT set device here — the model already knows where to go\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Batched inference\n",
    "prompts = test_df[\"question_text\"].tolist()\n",
    "outputs = []\n",
    "batch_size = 8\n",
    "\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    batch_prompts = prompts[i:i+batch_size]\n",
    "    results = generator(\n",
    "        batch_prompts,\n",
    "        max_new_tokens=128,\n",
    "        truncation=True,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # results is a list of lists, one list per prompt\n",
    "    for r in results:\n",
    "        outputs.append(r[0][\"generated_text\"])\n",
    "\n",
    "# Save outputs\n",
    "test_df[\"model_output\"] = outputs\n",
    "test_df.to_csv(\"test_with_qwen_outputs_cancer_gov.csv\", index=False)\n",
    "print(\"✅ Finished inference on GPU using accelerate. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e66ee2-41f6-43cb-98fc-f98273e7183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.04\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "test_df = pd.read_csv(\"test_with_qwen_outputs_cancer_gov.csv\")\n",
    "\n",
    "references = [[ref.split()] for ref in test_df[\"answer_text\"].tolist()]  # each ref must be a list of tokens\n",
    "hypotheses = [hyp.split() for hyp in test_df[\"model_output\"].tolist()]\n",
    "\n",
    "# Smoothing function helps with short sentences\n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "# Compute corpus BLEU\n",
    "bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smooth)\n",
    "print(f\"BLEU score: {bleu_score*100:.2f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb94dfd6-38fd-472f-a901-d43b56057c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# DataLoader to batch the validation set\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mval_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m predictions, references \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39130786-98df-4b87-b7f3-6c9afb2c9b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb7b04-2d1e-444a-95be-1bd570013e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen32b)",
   "language": "python",
   "name": "qwen32b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
